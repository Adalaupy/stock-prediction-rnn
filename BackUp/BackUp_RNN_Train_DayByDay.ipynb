{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnpALSqRoDdz"
   },
   "source": [
    "# Define Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4T6y0sbPprSz"
   },
   "outputs": [],
   "source": [
    "Epochs = 100\n",
    "Batch_Size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbkSAmVnoBRr"
   },
   "source": [
    "# Call Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7UsKhimpDMS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Y0ZB_H3PNtk"
   },
   "outputs": [],
   "source": [
    "%run Common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-UwCMswoGar"
   },
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bp53J0tfoWKj"
   },
   "source": [
    "## Create dataset Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rN6lx9RVqkrD"
   },
   "outputs": [],
   "source": [
    "def Create_Seq(data, p, Horizon):\n",
    "\n",
    "    X,y = [], []\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(len(data) - p - Horizon):\n",
    "\n",
    "        X.append(data[i:i + p])\n",
    "        y.append(data[i + p + Horizon ])\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(data) - p):\n",
    "\n",
    "        X.append(data[i:i + p])\n",
    "        y.append(data[i + p ])\n",
    "\n",
    "    return np.array(X) ,np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewLqMv-moaYb"
   },
   "source": [
    "## Build RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PthZaE2XtcbC"
   },
   "outputs": [],
   "source": [
    "def Build_Model(X_train, Horizon, p , times = 2):\n",
    "\n",
    "    \"\"\"\n",
    "    model = Sequential([])\n",
    "\n",
    "    # Encoder\n",
    "    model.add( LSTM(p, return_sequences=True, input_shape=(X_train.shape[1], 1)) )\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # LAST ENCODER LSTM â†’ 2D output\n",
    "    model.add(LSTM(p, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "    for _ in range(times):\n",
    "\n",
    "        model.add(LSTM(Horizon, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(25)))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam', loss='huber')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwr4BCyhojZL"
   },
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7Ub8SZRtgCC"
   },
   "outputs": [],
   "source": [
    "def Fit_Model(  X_train, y_train , X_test, y_test , Horizon, p , patience = 12):\n",
    "\n",
    "\n",
    "    model = Build_Model(X_train, Horizon, p )\n",
    "\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=Epochs,\n",
    "        batch_size = Batch_Size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"\\nTraining complete. Best model is in memory (epoch {len(history.history['loss'])}).\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mTLvs3Ooq4D"
   },
   "source": [
    "## Overall RNN Process for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "md3T5XlDop7T"
   },
   "outputs": [],
   "source": [
    "def RNN(data_df , p , t , Horizon ):\n",
    "\n",
    "    scaler = MinMaxScaler((0,1))\n",
    "    closes = data_df['Close'].values.reshape(-1, 1)\n",
    "    scale_data = scaler.fit_transform(closes)\n",
    "\n",
    "    X,y = Create_Seq(scale_data, p, Horizon)\n",
    "\n",
    "    v = int(len(X) * t )\n",
    "\n",
    "    X_train, X_test = X[:v] , X[v:]\n",
    "    y_train, y_test  = y[:v] , y[v:]\n",
    "\n",
    "\n",
    "    model = Fit_Model( X_train, y_train , X_test, y_test, Horizon, p)\n",
    "\n",
    "\n",
    "    pred_scaled = model.predict(X_test)\n",
    "\n",
    "    pred_price = scaler.inverse_transform(pred_scaled).flatten()\n",
    "    actu_price = scaler.inverse_transform(y_test).flatten()\n",
    "\n",
    "\n",
    "    data_df['Close_Pred'] = np.nan\n",
    "    # data_df.loc[data_df.index[v + p + Horizon:] , 'Close_Pred'] = pred_price\n",
    "    data_df.loc[data_df.index[v + p:] , 'Close_Pred'] = pred_price\n",
    "\n",
    "\n",
    "\n",
    "    # Skip part of the old data for better presentation\n",
    "    data_df = data_df.tail( len(pred_price) + 90)\n",
    "\n",
    "    mae = mean_absolute_error(actu_price, pred_price)\n",
    "\n",
    "\n",
    "    return mae, model, data_df,scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiRgFkt9pJsr"
   },
   "source": [
    "# Main Process of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mgy1pY3Dn7j_"
   },
   "outputs": [],
   "source": [
    "def Main_RNN(data, Horizon, min_p , gp ):\n",
    "\n",
    "    Code = data['Code'].drop_duplicates().values[0]\n",
    "\n",
    "    best_result_List = []\n",
    "\n",
    "    # For each validation fraction\n",
    "    for i in range(6,7):\n",
    "\n",
    "        t = i / 10\n",
    "        max_p = int(len(data) / 4) # not enough training data if p length too long\n",
    "\n",
    "        best_result = None\n",
    "\n",
    "        # For each seq_len\n",
    "        for p in range(min_p , max_p , int(min_p/gp) ):\n",
    "\n",
    "            print(\"=\" * 100)\n",
    "            print(f\"Training for Seq_len = {p}/{max_p} with validation fraction = {t} \")\n",
    "\n",
    "            mae, model, return_df, scaler = RNN(data , p , t , Horizon)\n",
    "\n",
    "            output_df = return_df.copy()\n",
    "\n",
    "            if best_result == None  :\n",
    "\n",
    "                best_result =  [mae, model, output_df, t, p , scaler]\n",
    "\n",
    "\n",
    "            elif mae < best_result[0]:\n",
    "\n",
    "                best_result = [mae, model, output_df, t, p , scaler]\n",
    "\n",
    "\n",
    "\n",
    "        best_result_List.append(best_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # BackUp Previous Folder\n",
    "    ThisFolder = f\"{RNN_PATH}/{Code}\"\n",
    "    CurrFolder = f\"{ThisFolder}/Current\"\n",
    "    BackUpName = f\"{ThisFolder}/{datetime.now().strftime(\"%Y%m%d\")}\"\n",
    "    fileName   = f'RNN_{Code}'\n",
    "\n",
    "\n",
    "    if os.path.exists(CurrFolder):\n",
    "\n",
    "        os.rename(CurrFolder , BackUpName)\n",
    "\n",
    "    os.makedirs(CurrFolder)\n",
    "\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(CurrFolder):\n",
    "        os.makedirs(CurrFolder)\n",
    "\n",
    "\n",
    "    # Save Best Result\n",
    "    for id in range(len(best_result_List)):\n",
    "\n",
    "        display_id = id + 1\n",
    "\n",
    "        best_result = best_result_List[id]\n",
    "\n",
    "        mae   = best_result[0]\n",
    "        model = best_result[1]\n",
    "        df    = best_result[2]\n",
    "        t     = best_result[3]\n",
    "        p     = best_result[4]\n",
    "        scler = best_result[5]\n",
    "\n",
    "\n",
    "        title = f'Id: {display_id}\\nRNN({p} with training Fraction = {t})'\n",
    "        name = f'RNN({p})'\n",
    "\n",
    "\n",
    "        Plot_Result(df, title, Code, model = 'RNN' , name = name , IsSave = True)\n",
    "\n",
    "\n",
    "        # Save Model + Scaler\n",
    "        model.save(f\"{CurrFolder}/{fileName}_{display_id}.keras\")\n",
    "        joblib.dump(scaler, f\"{CurrFolder}/{fileName}_{display_id}_scaler.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN3j9A5FpUAwcIeA/3dd5zD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
