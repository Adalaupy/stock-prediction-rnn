{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891f5f1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Define Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bca70b-511e-4338-b4ef-38115abbe054",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 100\n",
    "Batch_Size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cba5a6-83ba-410f-a9db-d18e44b2f5ec",
   "metadata": {},
   "source": [
    "# Call Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f72c0b-7185-463a-b311-48ae26983a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,RepeatVector, TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30754d2f-5d7a-4405-bb23-26310fee6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7990cb2-df54-489d-9169-d955ae8f6658",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746c19d-57b6-4f78-8c01-f5bc5c440190",
   "metadata": {},
   "source": [
    "## Create dataset Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d120ef-82bd-4592-b145-9c136a3b1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Seq(data, p , Horizon):\n",
    "\n",
    "    X, y , dates = [],[] , []\n",
    "\n",
    "    for i in range( len(data) - p - Horizon + 1 ):\n",
    "\n",
    "        X_data = data[i: i + p]\n",
    "        y_data = data[i + p : i + p + Horizon]\n",
    "\n",
    "        X.append(X_data['Scaled_Close'].values.reshape(-1,1) )\n",
    "        y.append(y_data['Scaled_Close'].values.reshape(-1,1))\n",
    "\n",
    "        dates.append(y_data['Date'].tolist())\n",
    "\n",
    "\n",
    "        # print(f'Use {X_data.iloc[0]['Date'].date()} to {X_data.iloc[-1]['Date'].date()} to predict stock price from {y_data.iloc[0]['Date'].date()} - {y_data.iloc[-1]['Date'].date()}')\n",
    "\n",
    "    return np.array(X), np.array(y), dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f76ba-8032-4fe9-9419-dd2f089a817c",
   "metadata": {},
   "source": [
    "## Build RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f64b2-9791-46cc-8848-a2f0ecba853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model( Horizon, p, units = 64, dropout = 0.2, layers = 2):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # -------------- Encoder --------------\n",
    "    for i in range(layers):\n",
    "\n",
    "        model.add(LSTM(units , \n",
    "                       input_shape=(p, 1) if i == 0 else None,\n",
    "                       return_sequences = True))\n",
    "        \n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    \n",
    "    # -------------- Bottleneck --------------\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    \n",
    "    \n",
    "    # -------------- RepeatVector --------------\n",
    "    model.add(RepeatVector(Horizon))\n",
    "\n",
    "\n",
    "    # -------------- Decoder --------------    \n",
    "    for _ in range(layers):\n",
    "        model.add(LSTM(units, return_sequences = True))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "\n",
    "    # ---------- Compile ----------\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',                \n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787e5ff-7a37-4927-8067-f2510e39e42c",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29072b24-9bd5-4de6-a75b-fae2b29ba69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit_Model(  X_train, y_train , X_test, y_test , Horizon, p , patience = 35):\n",
    "\n",
    "    model = Build_Model( Horizon , p )\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = patience,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=1e-6,\n",
    "        verbose = 0\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=Epochs,\n",
    "        batch_size = Batch_Size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e61016-3217-4f1b-9e4c-3fd3123b2a8c",
   "metadata": {},
   "source": [
    "## Handle Predict Result and Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f83ce-00dd-4c52-9c54-54d678bdcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Result_Agg(predicts,dates, scaler):\n",
    "\n",
    "    results = []\n",
    "    order_counter = 1\n",
    "\n",
    "    for predictList, dateList in zip(predicts,dates ):\n",
    "\n",
    "        for predict, date in zip(predictList , dateList):\n",
    "\n",
    "            result = {\"Date\": date.date(), \"Predict\" : predict[0], \"Order\": order_counter}\n",
    "\n",
    "            results.append(result)\n",
    "            order_counter += 1\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    aggregated_result = result_df.copy()\n",
    "    aggregated_result = aggregated_result.groupby(['Date']).agg(\n",
    "        count=('Predict', 'count'),\n",
    "        mean=('Predict', 'mean'),\n",
    "        Predict_Order_Sum=('Predict', lambda x: (x * result_df.loc[x.index, 'Order']).sum()),\n",
    "        Order_Sum=('Order', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    # Weighted Predict\n",
    "    aggregated_result['Weighted_Mean'] = aggregated_result['Predict_Order_Sum'] / aggregated_result['Order_Sum']\n",
    "    aggregated_result = aggregated_result.drop(columns=['Predict_Order_Sum', 'Order_Sum'])\n",
    "\n",
    "\n",
    "    # Rename + Scaler\n",
    "    aggregated_result = aggregated_result.rename(columns={'mean': 'Close_Pred'})\n",
    "    aggregated_result[\"Close_Pred\"] = scaler.inverse_transform(aggregated_result[['Close_Pred']])\n",
    "\n",
    "\n",
    "    result_df = result_df.rename(columns={'Predict': 'Close_Pred'})\n",
    "    result_df[\"Close_Pred\"] = scaler.inverse_transform(result_df[['Close_Pred']])\n",
    "\n",
    "    \n",
    "    \n",
    "    return aggregated_result, result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a58c16-bd5d-426a-9698-51df1cf4f5ab",
   "metadata": {},
   "source": [
    "## Overall RNN Process for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d8257-cb5b-49e8-90e2-5fe2254051ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(input_df, p, t, h , id, d ):\n",
    "\n",
    "    scaler = MinMaxScaler((0,1))\n",
    "    scaler.fit(input_df[['Close']])\n",
    "    input_df['Scaled_Close'] = scaler.transform(input_df[['Close']])\n",
    "\n",
    "\n",
    "    Code = input_df['Code'].values[0]\n",
    "    \n",
    "    X, y, dates = Create_Seq(input_df, p , h)\n",
    "\n",
    "\n",
    "    # Split Data to training and Validation dataset\n",
    "    v = int(len(X) * t)\n",
    "    X_train, X_test = X[:v], X[v:]\n",
    "    y_train, y_test = y[:v], y[v:]  \n",
    "    d_test = dates[v:]\n",
    "\n",
    "    \n",
    "    # Fit Model and predict validation dataset\n",
    "    model = Fit_Model(  X_train, y_train , X_test, y_test , h, p)\n",
    "\n",
    "    predicts = model.predict(X_test)\n",
    "    agg_df,indi_df = Predict_Result_Agg(predicts,d_test , scaler)\n",
    "\n",
    "\n",
    "    # Join 2 df\n",
    "    agg_df['Date'] = pd.to_datetime(agg_df['Date'])\n",
    "    merged_df = pd.merge(input_df[['Code', 'Date', 'Close']], agg_df[['Date', 'Close_Pred']], on='Date', how='left')\n",
    "\n",
    "\n",
    "    indi_df['Date'] = pd.to_datetime(indi_df['Date'])\n",
    "    indi_df = pd.merge( indi_df[['Date', 'Close_Pred' , 'Order']] , input_df[['Code', 'Date', 'Close']] , on='Date', how='left')\n",
    "    indi_df = indi_df[['Date', 'Close' , 'Close_Pred' , 'Order']]\n",
    "    \n",
    "\n",
    "    # Get Mean Absolute Error\n",
    "    merged_df_cleaned = merged_df.dropna(subset=['Close_Pred']).copy()\n",
    "    mae = mean_absolute_error(merged_df_cleaned['Close'], merged_df_cleaned['Close_Pred'])\n",
    "\n",
    "    mae_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "    mae_model = float(mae_loss(indi_df['Close'], indi_df['Close_Pred']).numpy())\n",
    "\n",
    "\n",
    "    print(f'Mean Absolute Error: {round(mae,3)} + {round(mae_model,3)}')\n",
    "\n",
    "    # Omit the old data for better presentation\n",
    "    data_df = merged_df.tail( len(predicts) + 50)       \n",
    "\n",
    "\n",
    "    \n",
    "    return mae,mae_model, model, data_df, indi_df\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
